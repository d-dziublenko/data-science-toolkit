version: "3.8"

# Define reusable components
x-common-variables: &common-variables
  PYTHONUNBUFFERED: "1"
  LOG_LEVEL: "INFO"
  TZ: "UTC"

services:
  # Main data science toolkit service
  ds-toolkit:
    build:
      context: .
      dockerfile: Dockerfile
      target: runtime # Use 'development' for dev environment
    image: ds-toolkit:latest
    container_name: ds-toolkit-main
    environment:
      <<: *common-variables
      JUPYTER_ENABLE_LAB: "yes"
      JUPYTER_TOKEN: "${JUPYTER_TOKEN:-datascience123}"
      MLFLOW_TRACKING_URI: "http://mlflow:5000"
    ports:
      - "8888:8888" # Jupyter Lab
      - "8000:8000" # API service (if enabled)
    volumes:
      # Mount data directory
      - ./data:/app/data
      # Mount outputs for persistence
      - ./outputs:/app/outputs
      # Mount models
      - ./models:/app/models
      # Mount configs
      - ./configs:/app/configs
      # Mount notebooks
      - ./notebooks:/app/notebooks
      # Mount logs
      - ./logs:/app/logs
      # Mount source code for development (comment out in production)
      - ./core:/app/core
      - ./models:/app/models
      - ./evaluation:/app/evaluation
      - ./pipelines:/app/pipelines
      - ./utils:/app/utils
    networks:
      - ds-network
    depends_on:
      - postgres
      - redis
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: "4"
          memory: 8G
        reservations:
          cpus: "2"
          memory: 4G

  # PostgreSQL database for storing results and metadata
  postgres:
    image: postgres:14-alpine
    container_name: ds-toolkit-postgres
    environment:
      POSTGRES_USER: "${POSTGRES_USER:-dsuser}"
      POSTGRES_PASSWORD: "${POSTGRES_PASSWORD:-dspassword}"
      POSTGRES_DB: "${POSTGRES_DB:-ds_toolkit}"
      PGDATA: /var/lib/postgresql/data/pgdata
    ports:
      - "5432:5432"
    volumes:
      - postgres-data:/var/lib/postgresql/data
    networks:
      - ds-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-dsuser}"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Redis for caching and task queuing
  redis:
    image: redis:7-alpine
    container_name: ds-toolkit-redis
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    networks:
      - ds-network
    restart: unless-stopped
    command: redis-server --appendonly yes
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  # MLflow for experiment tracking
  mlflow:
    image: ghcr.io/mlflow/mlflow:latest
    container_name: ds-toolkit-mlflow
    environment:
      BACKEND_STORE_URI: "postgresql://${POSTGRES_USER:-dsuser}:${POSTGRES_PASSWORD:-dspassword}@postgres:5432/${POSTGRES_DB:-ds_toolkit}"
      ARTIFACT_ROOT: "/mlflow/artifacts"
    ports:
      - "5000:5000"
    volumes:
      - mlflow-data:/mlflow
    networks:
      - ds-network
    depends_on:
      postgres:
        condition: service_healthy
    restart: unless-stopped
    command: >
      mlflow server
      --backend-store-uri postgresql://${POSTGRES_USER:-dsuser}:${POSTGRES_PASSWORD:-dspassword}@postgres:5432/${POSTGRES_DB:-ds_toolkit}
      --default-artifact-root /mlflow/artifacts
      --host 0.0.0.0
      --port 5000

  # Optional: Dask scheduler for distributed computing
  dask-scheduler:
    image: daskdev/dask:latest
    container_name: ds-toolkit-dask-scheduler
    ports:
      - "8786:8786" # Scheduler
      - "8787:8787" # Dashboard
    networks:
      - ds-network
    restart: unless-stopped
    command: ["dask-scheduler"]
    profiles:
      - distributed

  # Optional: Dask workers (scale as needed)
  dask-worker:
    image: daskdev/dask:latest
    container_name: ds-toolkit-dask-worker
    networks:
      - ds-network
    restart: unless-stopped
    command: ["dask-worker", "dask-scheduler:8786"]
    depends_on:
      - dask-scheduler
    deploy:
      replicas: 2
      resources:
        limits:
          cpus: "2"
          memory: 4G
    profiles:
      - distributed

  # Optional: MinIO for S3-compatible object storage
  minio:
    image: minio/minio:latest
    container_name: ds-toolkit-minio
    environment:
      MINIO_ROOT_USER: "${MINIO_ROOT_USER:-minioadmin}"
      MINIO_ROOT_PASSWORD: "${MINIO_ROOT_PASSWORD:-minioadmin}"
    ports:
      - "9000:9000" # API
      - "9001:9001" # Console
    volumes:
      - minio-data:/data
    networks:
      - ds-network
    restart: unless-stopped
    command: server /data --console-address ":9001"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3
    profiles:
      - storage

  # Optional: Apache Superset for data visualization
  superset:
    image: apache/superset:latest
    container_name: ds-toolkit-superset
    environment:
      SUPERSET_SECRET_KEY: "${SUPERSET_SECRET_KEY:-your_secret_key_here}"
      DATABASE_HOST: postgres
      DATABASE_USER: "${POSTGRES_USER:-dsuser}"
      DATABASE_PASSWORD: "${POSTGRES_PASSWORD:-dspassword}"
      DATABASE_DB: "${POSTGRES_DB:-ds_toolkit}"
    ports:
      - "8088:8088"
    networks:
      - ds-network
    depends_on:
      - postgres
      - redis
    restart: unless-stopped
    profiles:
      - visualization

  # Optional: Prometheus for monitoring
  prometheus:
    image: prom/prometheus:latest
    container_name: ds-toolkit-prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus-data:/prometheus
    networks:
      - ds-network
    restart: unless-stopped
    command:
      - "--config.file=/etc/prometheus/prometheus.yml"
      - "--storage.tsdb.path=/prometheus"
    profiles:
      - monitoring

  # Optional: Grafana for visualization
  grafana:
    image: grafana/grafana:latest
    container_name: ds-toolkit-grafana
    environment:
      GF_SECURITY_ADMIN_USER: "${GRAFANA_USER:-admin}"
      GF_SECURITY_ADMIN_PASSWORD: "${GRAFANA_PASSWORD:-admin}"
      GF_INSTALL_PLUGINS: "grafana-clock-panel,grafana-simple-json-datasource"
    ports:
      - "3000:3000"
    volumes:
      - grafana-data:/var/lib/grafana
      - ./monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards
      - ./monitoring/grafana/datasources:/etc/grafana/provisioning/datasources
    networks:
      - ds-network
    depends_on:
      - prometheus
    restart: unless-stopped
    profiles:
      - monitoring

# Define networks
networks:
  ds-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.28.0.0/16

# Define volumes for data persistence
volumes:
  postgres-data:
    driver: local
  redis-data:
    driver: local
  mlflow-data:
    driver: local
  minio-data:
    driver: local
  prometheus-data:
    driver: local
  grafana-data:
    driver: local
# Usage examples:
#
# Basic setup (just core services):
#   docker-compose up -d
#
# With distributed computing:
#   docker-compose --profile distributed up -d
#
# With storage service:
#   docker-compose --profile storage up -d
#
# With monitoring:
#   docker-compose --profile monitoring up -d
#
# With visualization tools:
#   docker-compose --profile visualization up -d
#
# Everything:
#   docker-compose --profile distributed --profile storage --profile monitoring --profile visualization up -d
#
# Scale workers:
#   docker-compose --profile distributed up -d --scale dask-worker=4
#
# View logs:
#   docker-compose logs -f ds-toolkit
#
# Enter container:
#   docker-compose exec ds-toolkit bash
#
# Stop all services:
#   docker-compose down
#
# Stop and remove volumes:
#   docker-compose down -v
